{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of New York City Taxi Data Report\n",
        "\n",
        "\n",
        " **Written by:**\n",
        "*   FAIZA ROUIBAH  \n",
        "*   IKRAM MAGOUSSI"
      ],
      "metadata": {
        "id": "XTuU55q0IAfg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Table of Contents**\n",
        "\n",
        "Introduction\n",
        "\n",
        "Project Steps\n",
        "\n",
        "*   Initialize PySpark Session\n",
        "*   Data Loading\n",
        "*   Data Cleaning\n",
        "*   Data Enrichment\n",
        "*   Query 1: Utilization\n",
        "*   Query 2: Average Time to Next Fare\n",
        "*   Query 3: Intra-Borough Trips\n",
        "*   Query 4: Inter-Borough Trips\n",
        "\n",
        "Conclusion"
      ],
      "metadata": {
        "id": "D_NWwEh4GPde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "Analyzing transportation data is crucial for understanding urban mobility, and the New York City taxi dataset serves as a valuable resource for this study. This project focuses on four main objectives:\n",
        "\n",
        "\n",
        "1.   **Utilization of taxis**: Assessing the fraction of time a taxi is on the road and occupied by passengers.\n",
        "2.   **Average time to next fare**: Calculating the waiting time between dropping off a passenger and picking up the next one.\n",
        "\n",
        "1.    **Intra-borough trips**: Identifying the number of trips that start and end within the same borough.\n",
        "2.  **Inter-borough trips:** Counting trips that begin in one borough and end in another\n",
        "\n",
        "We will utilize PySpark for handling large data volumes and Shapely for enriching geographic information. The analysis aims to provide meaningful insights into transportation dynamics in New York City.\n"
      ],
      "metadata": {
        "id": "FSkwOUIpCrXW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0urZEAqUquo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b0cb07-a841-418e-a6f1-e6b2edd7b74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark shapely"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing Spark and Loading Data**\n",
        "In this section, we begin by initializing a Spark session, enabling us to use\n",
        "Apache Spark's data processing capabilities. Next, we load the taxi trip data from a CSV file. The header=True option tells Spark that the first row contains column names, and inferSchema=True allows Spark to automatically detect the data types of each column\n",
        "\n"
      ],
      "metadata": {
        "id": "xXHblmJ5m6uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"NYC Taxi Data Analysis\").getOrCreate()\n",
        "# Load taxi data CSV file\n",
        "taxi_df = spark.read.csv('/content/sample_data/Sample NYC Data.csv', header=True, inferSchema=True)\n",
        "# Display first few rows to check the data\n",
        "taxi_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-oIldYMVTXR",
        "outputId": "4ad5afca-c654-446d-ae86-19c78584b1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|pickup_datetime|dropoff_datetime|passenger_count|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N| 01-01-13 15:11|  01-01-13 15:18|              4|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
            "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 06-01-13 00:18|  06-01-13 00:22|              1|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
            "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 05-01-13 18:49|  05-01-13 18:54|              1|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
            "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:54|  07-01-13 23:58|              2|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
            "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:25|  07-01-13 23:34|              1|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Data Cleaning: Filtering Invalid and Inconsistent Entries**\n",
        "In this section, we clean the taxi data by applying two filters:\n",
        "\n",
        "Filter out invalid drop-off locations: We remove rows where both\n",
        "\n",
        "\n",
        "\n",
        "1.   **Filter out invalid drop-off locations:** We remove rows where both dropoff_longitude and dropoff_latitude are set to 0, which usually indicates missing or incorrect data\n",
        "*   **Filter out inconsistent time entries:** We ensure that the pickup_datetime occurs before the dropoff_datetime for each trip, which removes records with incorrect timestamps.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Rsy7jkUynkuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import unix_timestamp\n",
        "# Filter rows where dropoff_longitude and dropoff_latitude are not equal to 0\n",
        "taxi_data_cleaned = taxi_df.filter(~((F.col('dropoff_longitude') == 0) & (F.col('dropoff_latitude') == 0)))\n",
        "# Filter so that pickup_datetime is before dropoff_datetime\n",
        "taxi_data_cleaned = taxi_data_cleaned.filter(F.col(\"pickup_datetime\") < F.col(\"dropoff_datetime\") )\n",
        "# Show the cleaned DataFrame\n",
        "taxi_data_cleaned.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvY3J2XZZfX-",
        "outputId": "469a6f07-9d4a-4863-f0b1-863794daee4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|pickup_datetime|dropoff_datetime|passenger_count|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N| 01-01-13 15:11|  01-01-13 15:18|              4|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
            "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 06-01-13 00:18|  06-01-13 00:22|              1|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
            "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N| 05-01-13 18:49|  05-01-13 18:54|              1|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
            "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:54|  07-01-13 23:58|              2|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
            "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N| 07-01-13 23:25|  07-01-13 23:34|              1|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
            "+--------------------+--------------------+---------+---------+------------------+---------------+----------------+---------------+----------------+---------------+-----------------+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Duration Calculation**\n",
        "In this section, we perform the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   **Date column conversion:** We convert the pickup_datetime and dropoff_datetime columns to the dd-MM-yy HH:mm format using to_timestamp. This ensures that the date and time values are interpreted correctly.\n",
        "2.   **Trip duration calculation:** We add a Duration column that represents the trip duration in seconds, calculated as the difference between dropoff_datetime and pickup_datetime. Then, we add a Duration_Minutes column to express this duration in minutes.\n",
        "3.   **Filtering valid records:** We keep only trips with durations between 0 and 14,400 seconds (4 hours) to eliminate outliers.\n",
        "\n",
        "\n",
        "Finally, we display the first 10 rows with the new Duration and Duration_Minutes columns to verify the result.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sCRCfdzxp5u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "#Convert date columns with the correct format\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\n",
        "    \"pickup_datetime\",\n",
        "    F.to_timestamp(F.col(\"pickup_datetime\"), \"dd-MM-yy HH:mm\")\n",
        ").withColumn(\n",
        "    \"dropoff_datetime\",\n",
        "    F.to_timestamp(F.col(\"dropoff_datetime\"), \"dd-MM-yy HH:mm\")\n",
        ")\n",
        "# calculate the duration in seconds\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\n",
        "    \"Duration\",\n",
        "    F.unix_timestamp(\"dropoff_datetime\") - F.unix_timestamp(\"pickup_datetime\")\n",
        ").withColumn(\n",
        "    \"Duration_Minutes\",\n",
        "    F.col(\"Duration\") / 60  # Convert duration to minutes\n",
        ")\n",
        "# Filter valid records\n",
        "taxi_data_cleaned = taxi_data_cleaned.filter(\n",
        "    (F.col(\"Duration\") >= 0) & (F.col(\"Duration\") <= 14400)  # 14400 seconds = 4 hours\n",
        ")\n",
        "# Show final results\n",
        "taxi_data_cleaned.select(\"pickup_datetime\", \"dropoff_datetime\", \"Duration\", \"Duration_Minutes\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzXkL68g_GeV",
        "outputId": "4cefa5da-60c2-423f-aa4d-66b0c5b1119a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-------------------+--------+----------------+\n",
            "|    pickup_datetime|   dropoff_datetime|Duration|Duration_Minutes|\n",
            "+-------------------+-------------------+--------+----------------+\n",
            "|2013-01-01 15:11:00|2013-01-01 15:18:00|     420|             7.0|\n",
            "|2013-01-06 00:18:00|2013-01-06 00:22:00|     240|             4.0|\n",
            "|2013-01-05 18:49:00|2013-01-05 18:54:00|     300|             5.0|\n",
            "|2013-01-07 23:54:00|2013-01-07 23:58:00|     240|             4.0|\n",
            "|2013-01-07 23:25:00|2013-01-07 23:34:00|     540|             9.0|\n",
            "|2013-01-07 15:27:00|2013-01-07 15:38:00|     660|            11.0|\n",
            "|2013-01-08 11:01:00|2013-01-08 11:08:00|     420|             7.0|\n",
            "|2013-01-07 12:39:00|2013-01-07 13:10:00|    1860|            31.0|\n",
            "|2013-01-07 18:15:00|2013-01-07 18:20:00|     300|             5.0|\n",
            "|2013-01-07 15:33:00|2013-01-07 15:49:00|     960|            16.0|\n",
            "+-------------------+-------------------+--------+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query** 1 : **Taxi Utilization Analysis**\n",
        "\n",
        "In this section, we analyze the usage of taxis by calculating the waiting time between trips and the duration of rides. We determine the idle time between trips and filter the records to keep only those with reasonable waiting times. By aggregating this data, we assess the efficiency of taxis through a utilization metric. This analysis helps us understand their operational performance and identify optimization opportunities. Finally, we present the results for each taxi, including the total trip duration, total waiting time, and utilization rate."
      ],
      "metadata": {
        "id": "q_p5UiKrtdea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, Window\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.functions import col, unix_timestamp, lag, sum as spark_sum\n",
        "\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\"pickup_datetime\", F.to_timestamp(\"pickup_datetime\")) \\\n",
        "                                       .withColumn(\"dropoff_datetime\", F.to_timestamp(\"dropoff_datetime\"))\n",
        "\n",
        "# Define window partitioned by 'medallion' and ordered by 'pickup_datetime'\n",
        "window_spec = Window.partitionBy(\"medallion\").orderBy(\"pickup_datetime\")\n",
        "\n",
        "# Create a window partitioned by 'medallion' and ordered by 'pickup_datetime'\n",
        "windowSpec = Window.partitionBy(\"medallion\").orderBy(\"pickup_datetime\")\n",
        "\n",
        "# Calculate the waiting time (inactivity) between the dropoff of one trip and the pickup of the next\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\n",
        "    \"next_pickup_datetime\",\n",
        "    F.lead(\"pickup_datetime\").over(windowSpec)\n",
        ").withColumn(\n",
        "    \"idle_time\",\n",
        "    (F.unix_timestamp(\"next_pickup_datetime\") - F.unix_timestamp(\"dropoff_datetime\")) / 60\n",
        ")\n",
        "# Filter idle times greater than 4 hours (240 minutes)\n",
        "taxi_data_cleaned = taxi_data_cleaned.filter(col(\"idle_time\") <= 240)\n",
        "\n",
        "# Calculate travel time\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\"trip_duration\",\n",
        "                                             (unix_timestamp(\"dropoff_datetime\") - unix_timestamp(\"pickup_datetime\")) / 60)  # Durée en minutes\n",
        "\n",
        "# Calculate total travel time and idle time per taxi\n",
        "utilization_df = taxi_data_cleaned.groupBy(\"medallion\") \\\n",
        "    .agg(\n",
        "        spark_sum(\"trip_duration\").alias(\"total_trip_duration\"),\n",
        "        spark_sum(\"idle_time\").alias(\"total_idle_time\")\n",
        "    ).withColumn(\n",
        "        \"utilization\",\n",
        "        F.when((col(\"total_trip_duration\") + col(\"total_idle_time\")) > 0,\n",
        "                col(\"total_trip_duration\") / (col(\"total_trip_duration\") + col(\"total_idle_time\"))\n",
        "        ).otherwise(0)\n",
        "    )\n",
        "\n",
        "#Show results\n",
        "utilization_df.select(\"medallion\", \"total_trip_duration\", \"total_idle_time\", \"utilization\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qem9N0R3bZgL",
        "outputId": "356c7a92-2042-41e3-fcdd-0e2d705b2ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------------+---------------+-------------------+\n",
            "|           medallion|total_trip_duration|total_idle_time|        utilization|\n",
            "+--------------------+-------------------+---------------+-------------------+\n",
            "|000318C2E3E638158...|              107.0|          120.0| 0.4713656387665198|\n",
            "|002B4CFC5B8920A87...|              163.0|          295.0| 0.3558951965065502|\n",
            "|002E3B405B6ABEA23...|              161.0|          269.0| 0.3744186046511628|\n",
            "|0030AD2648D81EE87...|                9.0|           12.0|0.42857142857142855|\n",
            "|0035520A854E4F276...|              131.0|          248.0|0.34564643799472294|\n",
            "|0036961468659D0BF...|              177.0|          329.0|0.34980237154150196|\n",
            "|003889E315BFDD985...|               72.0|          158.0| 0.3130434782608696|\n",
            "|0038EF45118925A51...|              166.0|          252.0|0.39712918660287083|\n",
            "|003D87DB553C6F00F...|              194.0|          203.0|0.48866498740554154|\n",
            "|003EEA559FA618008...|              235.0|          644.0|  0.267349260523322|\n",
            "|0053334C798EC6C8E...|              127.0|          374.0|0.25349301397205587|\n",
            "|005DED7D6E6C45441...|              150.0|          196.0|0.43352601156069365|\n",
            "|005F00B38F46E2100...|              296.0|          703.0| 0.2962962962962963|\n",
            "|00790C7BAD30B7A9E...|              166.0|          422.0|  0.282312925170068|\n",
            "|0081EFFCBB2AD30F9...|              127.0|          339.0|0.27253218884120173|\n",
            "|00891E0B23CDA09C3...|              172.0|          166.0| 0.5088757396449705|\n",
            "|0094A03FFE6BAFBE0...|              135.0|           90.0|                0.6|\n",
            "|009D3CCA83486B03F...|              317.0|          682.0| 0.3173173173173173|\n",
            "|00A49907F0F143BD4...|              143.0|          490.0| 0.2259083728278041|\n",
            "|00A74F4CAB098B3A3...|              311.0|          585.0| 0.3470982142857143|\n",
            "+--------------------+-------------------+---------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Enrichment**\n",
        "\n",
        "In this data enrichment phase, we loaded the geographical information of New York's boroughs from a GeoJSON file. This file contains polygons representing the boundaries of each borough, allowing us to identify the borough corresponding to each taxi trip's coordinates. After loading the data, we broadcasted it to all Spark workers to ensure quick access during calculations"
      ],
      "metadata": {
        "id": "R_H_Bwlk2jAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the geojson file\n",
        "import json\n",
        "with open('/content/sample_data/nyc-boroughs.geojson', 'r') as file:\n",
        "    geojson_data = json.load(file)"
      ],
      "metadata": {
        "id": "Q2DRykYBDFaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Broadcasting the geojson data to the workers\n",
        "broadcast_geojson = spark.sparkContext.broadcast(geojson_data)\n",
        "\n",
        "# Verify that the broadcast has been done\n",
        "assert broadcast_geojson.value == geojson_data, \"Broadcasting failed!\""
      ],
      "metadata": {
        "id": "Ivjy75cCDnZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from shapely.geometry import Point, shape\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def preprocess_geojson(geojson_boroughs: dict) -> list:\n",
        "    \"\"\"\n",
        "    Preprocesses the geojson data to create a sorted list of polygons.\n",
        "\n",
        "    Args:\n",
        "    - geojson_boroughs (dict): The geojson data containing polygons and their properties.\n",
        "\n",
        "    Returns:\n",
        "    - list: A sorted list of tuples where each tuple contains a polygon and its associated properties.\n",
        "    \"\"\"\n",
        "\n",
        "    polygons_with_props = [\n",
        "        (shape(feature['geometry']), feature['properties'])\n",
        "        for feature in geojson_boroughs['features']\n",
        "    ]\n",
        "    return sorted(polygons_with_props, key=lambda x: (x[1]['boroughCode'], -x[0].area))\n",
        "\n",
        "def get_borough(longitude: float, latitude: float, sorted_polygons: list) -> str:\n",
        "    \"\"\"\n",
        "    Return the borough name for a given longitude and latitude.\n",
        "\n",
        "    Args:\n",
        "    - longitude (float): Longitude of the location.\n",
        "    - latitude (float): Latitude of the location.\n",
        "    - sorted_polygons (list): List of preprocessed polygons for lookup.\n",
        "\n",
        "    Returns:\n",
        "    - str: Name of the borough if the point falls within a polygon, otherwise None.\n",
        "    \"\"\"\n",
        "    point = Point(longitude, latitude)\n",
        "    for polygon, properties in sorted_polygons:\n",
        "        if polygon.contains(point):\n",
        "            return properties['borough']\n",
        "    return None\n",
        "# Preprocess polygons and then broadcast\n",
        "sorted_polygons = preprocess_geojson(broadcast_geojson.value)\n",
        "sorted_polygons_broadcast = spark.sparkContext.broadcast(sorted_polygons)\n",
        "\n",
        "# Convert the get_borough function to a UDF using lambda to pass the broadcasted sorted_polygons\n",
        "borough_udf = udf(lambda lon, lat: get_borough(lon, lat, sorted_polygons_broadcast.value), StringType())"
      ],
      "metadata": {
        "id": "903xQ4KhDyc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use withColumn for pickup_borough\n",
        "taxi_data_cleaned = (taxi_data_cleaned\n",
        "                      .withColumn(\"pickup_borough\",\n",
        "                                  borough_udf(col(\"pickup_longitude\"), col(\"pickup_latitude\"))))\n",
        "\n",
        "# Use withColumn again for dropoff_borough\n",
        "taxi_data_cleaned = (taxi_data_cleaned\n",
        "                      .withColumn(\"dropoff_borough\",\n",
        "                                  borough_udf(col(\"dropoff_longitude\"), col(\"dropoff_latitude\"))))\n",
        "\n",
        "# Show results\n",
        "taxi_data_cleaned.limit(5).select(\"pickup_borough\", \"dropoff_borough\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDoEtJPqEBUo",
        "outputId": "17406bc8-a8fb-4161-ea50-64a7f6c74a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------------+\n",
            "|pickup_borough|dropoff_borough|\n",
            "+--------------+---------------+\n",
            "|Manhattan     |Manhattan      |\n",
            "|Manhattan     |Manhattan      |\n",
            "|Manhattan     |Manhattan      |\n",
            "|Manhattan     |Manhattan      |\n",
            "|Manhattan     |Manhattan      |\n",
            "+--------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude']\n",
        "taxi_data_cleaned = taxi_data_cleaned.drop(*columns_to_drop)"
      ],
      "metadata": {
        "id": "PhOaB_UEEbTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display distinct pickup boroughs\n",
        "taxi_data_cleaned.select(\"pickup_borough\").distinct().show()\n",
        "\n",
        "# Display distinct dropoff boroughs\n",
        "taxi_data_cleaned.select(\"dropoff_borough\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4a1Aq4aEpJO",
        "outputId": "591940c0-cdf7-4ca5-fa04-ece601f2ba97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|pickup_borough|\n",
            "+--------------+\n",
            "|        Queens|\n",
            "|      Brooklyn|\n",
            "| Staten Island|\n",
            "|     Manhattan|\n",
            "|         Bronx|\n",
            "|          NULL|\n",
            "+--------------+\n",
            "\n",
            "+---------------+\n",
            "|dropoff_borough|\n",
            "+---------------+\n",
            "|         Queens|\n",
            "|       Brooklyn|\n",
            "|  Staten Island|\n",
            "|      Manhattan|\n",
            "|          Bronx|\n",
            "|           NULL|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count rows where pickup_borough is \"null\"\n",
        "pickup_null_count = taxi_data_cleaned.filter(taxi_data_cleaned[\"pickup_borough\"].isNull()).count()\n",
        "\n",
        "# Count rows where dropoff_borough is \"null\"\n",
        "dropoff_null_count = taxi_data_cleaned.filter(taxi_data_cleaned[\"dropoff_borough\"].isNull()).count()\n",
        "\n",
        "print(f\"Number of rows with 'null' pickup_borough: {pickup_null_count}\")\n",
        "print(f\"Number of rows with 'null' dropoff_borough: {dropoff_null_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pWKU_ABFBh1",
        "outputId": "736f0f39-8050-4e06-f038-9e4556a60ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows with 'null' pickup_borough: 163\n",
            "Number of rows with 'null' dropoff_borough: 369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxi_data_cleaned = taxi_data_cleaned.filter(\n",
        "    (taxi_data_cleaned[\"pickup_borough\"].isNotNull()) &\n",
        "    (taxi_data_cleaned[\"dropoff_borough\"].isNotNull())\n",
        ")"
      ],
      "metadata": {
        "id": "S8pjZCE6Facb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display distinct pickup boroughs\n",
        "taxi_data_cleaned.select(\"pickup_borough\").distinct().show()\n",
        "\n",
        "# Display distinct dropoff boroughs\n",
        "taxi_data_cleaned.select(\"dropoff_borough\").distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4ia1fBXFo9p",
        "outputId": "54a9884d-c398-492c-cde2-721d230d9a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|pickup_borough|\n",
            "+--------------+\n",
            "|        Queens|\n",
            "|      Brooklyn|\n",
            "| Staten Island|\n",
            "|     Manhattan|\n",
            "|         Bronx|\n",
            "+--------------+\n",
            "\n",
            "+---------------+\n",
            "|dropoff_borough|\n",
            "+---------------+\n",
            "|         Queens|\n",
            "|       Brooklyn|\n",
            "|  Staten Island|\n",
            "|      Manhattan|\n",
            "|          Bronx|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape after cleaning\n",
        "print(taxi_data_cleaned.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBbTG1wN1ofZ",
        "outputId": "f350be95-c8c2-464c-958e-37f5c1917728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 2: Average Time to Find the Next Fare**\n",
        "\n",
        "In this section, we calculate the average time a taxi takes to find its next fare, broken down by destination borough. To achieve this, we use the lead function to determine the pickup time of the next trip for each taxi. We then measure the time difference, in seconds, between the end of the current trip (drop-off) and the start of the next one (pickup) to obtain the waiting time. The data is grouped by taxi identifier (hack_license) and drop-off borough to calculate the average waiting time for each taxi in each borough.\n",
        "\n",
        "**The objective** of this analysis is to understand the operational efficiency of taxis by identifying the average waiting times for finding a new fare in different boroughs, which can help optimize deployment strategies and enhance the customer experience"
      ],
      "metadata": {
        "id": "Pa4kp2scwDmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Window\n",
        "from pyspark.sql.functions import lead, col, avg, when\n",
        "\n",
        "# Define a window specification\n",
        "windowSpec = Window.partitionBy(\"hack_license\").orderBy(\"pickup_datetime\")\n",
        "\n",
        "# Get the pickup timestamp of the next trip for each taxi's row\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\"next_pickup_timestamp\",\n",
        "                                                  lead(\"pickup_datetime\").over(windowSpec))\n",
        "\n",
        "# Compute the time difference in seconds between dropoff and the next pickup\n",
        "taxi_data_cleaned = taxi_data_cleaned.withColumn(\"waiting_time\",\n",
        "           when(col(\"next_pickup_timestamp\").isNotNull(),\n",
        "                (col(\"next_pickup_timestamp\").cast(\"long\") - col(\"dropoff_datetime\").cast(\"long\")))\n",
        "           .otherwise(None))\n",
        "\n",
        "# Compute the average waiting time for each taxi in each dropoff borough\n",
        "average_waiting_time_per_taxi_per_borough = (taxi_data_cleaned.groupBy(\"hack_license\", \"dropoff_borough\")\n",
        "                                .agg(avg(\"waiting_time\").alias(\"avg_waiting_time_seconds\"))\n",
        "                                .orderBy(\"hack_license\", \"dropoff_borough\"))\n",
        "\n",
        "#Droping the no needed any longer column\n",
        "taxi_data_cleaned = taxi_data_cleaned.drop(\"next_pickup_timestamp\", \"waiting_time\")\n",
        "\n",
        "# Show the results\n",
        "average_waiting_time_per_taxi_per_borough.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjdvV5jyJTBS",
        "outputId": "26f31bfd-04bf-4a3d-fd79-21e2e3ae052a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+------------------------+\n",
            "|        hack_license|dropoff_borough|avg_waiting_time_seconds|\n",
            "+--------------------+---------------+------------------------+\n",
            "|001C8AAB90AEE49F3...|       Brooklyn|                  5940.0|\n",
            "|001C8AAB90AEE49F3...|      Manhattan|                  3510.0|\n",
            "|0025133AD810DBE80...|      Manhattan|                  2400.0|\n",
            "|002C093A2CB9FD40C...|       Brooklyn|                   450.0|\n",
            "|002C093A2CB9FD40C...|      Manhattan|                  1105.0|\n",
            "|002C093A2CB9FD40C...|         Queens|                  1020.0|\n",
            "|00447A6197DBB329F...|       Brooklyn|                  2940.0|\n",
            "|00447A6197DBB329F...|      Manhattan|                  5460.0|\n",
            "|00447A6197DBB329F...|         Queens|                  4800.0|\n",
            "|0046F1E91AA13DEDE...|      Manhattan|       582.3529411764706|\n",
            "|00567B1CBFD51DDFA...|      Manhattan|                   504.0|\n",
            "|006114F940CB87B3A...|      Manhattan|                   603.0|\n",
            "|006114F940CB87B3A...|         Queens|                  3840.0|\n",
            "|006313464EC98A24B...|      Manhattan|      1421.0526315789473|\n",
            "|006B6BD90C7B5C985...|      Manhattan|       686.6666666666666|\n",
            "|00711D0CC3FB5BC90...|      Manhattan|                  1380.0|\n",
            "|00711D0CC3FB5BC90...|         Queens|                 48780.0|\n",
            "|007357E7FFE212879...|       Brooklyn|                  1120.0|\n",
            "|007357E7FFE212879...|      Manhattan|       681.4285714285714|\n",
            "|007439EEDB510EF82...|       Brooklyn|                    NULL|\n",
            "+--------------------+---------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 3: Intra-Borough Trips**\n",
        "\n",
        "Dans cette section, nous déterminons le nombre de trajets de taxi qui ont commencé et terminé dans le même borough. En filtrant le jeu de données pour inclure uniquement les trajets où le borough de prise en charge correspond au borough de dépôt"
      ],
      "metadata": {
        "id": "QlavZ8f0yImc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, col\n",
        "\n",
        "same_borough_trips = taxi_data_cleaned.filter(col(\"pickup_borough\") == col(\"dropoff_borough\"))\n",
        "\n",
        "# Count the number of these trips grouped by borough\n",
        "count_same_borough_trips = same_borough_trips.agg(count(\"*\").alias(\"number_of_trips\"))\\\n",
        "                                             .orderBy(\"number_of_trips\", ascending=False)\n",
        "\n",
        "count_same_borough_trips.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H_hm3VTNOWi",
        "outputId": "68348abe-57c8-4646-d47f-2cd54a23ea4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|number_of_trips|\n",
            "+---------------+\n",
            "|          78976|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Query 4: Inter-Borough Trips**\n",
        "\n",
        "In this section, we analyze inter-borough trips by filtering the data to identify rides where the pickup borough differs from the drop-off borough. This allows us to count the number of trips made between different boroughs.\n",
        "\n",
        " **The objective of this analysis** is to identify trends in inter-borough travel in order to optimize taxi services by adjusting resources to meet passenger needs and improve transportation efficiency."
      ],
      "metadata": {
        "id": "E3ddekv2zAkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, col\n",
        "\n",
        "# Filter rows where pickup_borough is not equal to dropoff_borough\n",
        "inter_borough_trips = taxi_data_cleaned.filter(col(\"pickup_borough\") != col(\"dropoff_borough\"))\n",
        "\n",
        "# Count the number of these trips grouped by pickup and dropoff boroughs\n",
        "count_inter_borough_trips = inter_borough_trips.agg(count(\"*\").alias(\"number_of_trips\"))\\\n",
        "                                               .orderBy(\"number_of_trips\", ascending=False)\n",
        "\n",
        "count_inter_borough_trips.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YykL2KjFUX2b",
        "outputId": "c8931793-b71f-41b4-d70e-11a9e33e9a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n",
            "|number_of_trips|\n",
            "+---------------+\n",
            "|           9490|\n",
            "+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This project highlights key trends in urban mobility, offering insights to improve the efficiency and accessibility of transportation services. By identifying patterns and mobility behaviors, this analysis provides a strong foundation for optimizing resource allocation, better meeting user needs, and enhancing the customer experience. Future analyses could expand by integrating additional data, such as peak hours and new mobility habits, to support even more precise and tailored planning"
      ],
      "metadata": {
        "id": "EZcRSxGbBxGx"
      }
    }
  ]
}